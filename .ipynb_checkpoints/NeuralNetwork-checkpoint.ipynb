{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ade0e88",
   "metadata": {},
   "source": [
    "# Red Neuronal BrandFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce014b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b1a0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cv2 as cv\n",
    "    import os\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    from keras.applications import VGG19\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from PIL import Image  \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    import subprocess\n",
    "    import sys\n",
    "\n",
    "    def install(package):\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "    install('opencv-python')\n",
    "    install('tensorflow')\n",
    "    install('matplotlib')\n",
    "    install('numpy')\n",
    "    install('scikit-learn')\n",
    "    install('seaborn')\n",
    "\n",
    "\n",
    "    import cv2 as cv\n",
    "    import os\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    from keras.applications import VGG19\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from PIL import Image \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa640b",
   "metadata": {},
   "source": [
    "## Función data_evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db4cde",
   "metadata": {},
   "source": [
    "La siguiente función permite visualizar la evolución del rendimiento de un modelo durante el entrenamiento y la validación, proporcionando información sobre la precisión y la pérdida en cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde42684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_evolution(history):\n",
    "    plt.subplots_adjust(left = None, bottom = None, right = 1.5, top = None, wspace = 0.5)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "    plt.ylim([0.,1.])\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "    plt.plot(history.history['val_loss'], label='Validación')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489b9d5",
   "metadata": {},
   "source": [
    "## Función data_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc2d9d3",
   "metadata": {},
   "source": [
    "La siguiente función calcula y visualiza una matriz de confusión para evaluar el rendimiento de un modelo de clasificación en términos de las etiquetas verdaderas y las etiquetas predichas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e9c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_confusion_matrix(validation_generator, labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Generar predicciones en el conjunto de datos de validación\n",
    "    y_pred = model.predict_generator(validation_generator)\n",
    "\n",
    "    # Convertir las predicciones en etiquetas de clase (por ejemplo, asignar la clase con mayor probabilidad)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Obtener las etiquetas reales del conjunto de datos de validación\n",
    "    y_true = validation_generator.classes\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    confusion_mtx = confusion_matrix(y_true, y_pred)\n",
    "  \n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_mtx, xticklabels=labels, yticklabels=labels, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.xlabel('Etiqueta Predicha')\n",
    "    plt.ylabel('Etiqueta Real')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42cf6e5",
   "metadata": {},
   "source": [
    "## Función image_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2cbc09",
   "metadata": {},
   "source": [
    "La siguiente dunción calcula el promedio de una lista de números que representa las proporciones de altura/ancho de una colección de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089b2e44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ratio of width to height is 0.8033851860097734\n"
     ]
    }
   ],
   "source": [
    "def image_average(train_path):\n",
    "\n",
    "    listdir = os.listdir(train_path)\n",
    "    ratios_sub = []\n",
    "    ratios = []\n",
    "\n",
    "    for imdir in listdir:\n",
    "        imlist = os.listdir(os.path.join(train_path, imdir))  \n",
    "        for im in imlist:\n",
    "            im = cv.imread(os.path.join(train_path,imdir,im))\n",
    "            ratio = (im.shape[0] / im.shape[1]) #height/width ratio\n",
    "            ratios_sub.append((ratio))\n",
    "        ratios_sub_ave= sum(ratios_sub) / len(ratios_sub)\n",
    "        ratios.append((ratios_sub_ave))\n",
    "    return sum(ratios) / len(ratios)\n",
    "\n",
    "    \n",
    "ratio = image_average(\"Car_Brand_Logos/Train\")\n",
    "\n",
    "print(\"Average ratio of width to height is {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec678bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 240)\n"
     ]
    }
   ],
   "source": [
    "width = 240\n",
    "height= int(width*ratio)\n",
    "input_shape = (height,width)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04131861",
   "metadata": {},
   "source": [
    "## Definición de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b02211",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = width, height \n",
    "train_data_dir = 'Car_Brand_Logos/Train/'\n",
    "validation_data_dir = 'Car_Brand_Logos/Test/'\n",
    "\n",
    "numberOfClass = 8\n",
    "batch_size = 8\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa61551",
   "metadata": {},
   "source": [
    "# Mejorar del rendimiento y generalización del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8567d38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2513 images belonging to 8 classes.\n",
      "Found 400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Normalización de las imágenes (dividir los valores de píxeles por 255) y aplicación de \n",
    "# transformaciones aleatorias a las imágenes de entrenamiento para aumentar la diversidad \n",
    "# y cantidad de ejemplos disponibles\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    shear_range = 0.90,\n",
    "    zoom_range = 0.90,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True) \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# A continuación, se definen los generadores de lotes, que permiten cargar y procesar las imágenes en lotes \n",
    "# más pequeños en lugar de cargar todas las imágenes en la memoria a la vez. \n",
    "# Es importante destacar el redimensionamiento de las imágenes a un tamaño específico, utilizando el argumento \n",
    "# \"target_size\", es importante para asegurarse de que todas las imágenes tengan dimensiones uniformes.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515fc23",
   "metadata": {},
   "source": [
    "## Definición y entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34864758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 es una red neuronal convolucional ampliamente utilizada y entrenada en el conjunto de datos \"Imagenet\", \n",
    "# que contiene una gran cantidad de imágenes clasificadas en diversas categorías.\n",
    "\n",
    "# Se crea una instancia del modelo VGG19 llamada \"vgg\" utilizando la función \"VGG19\" de Keras. Se especifica \n",
    "# \"include_top=False\" para excluir la capa de clasificación final de VGG19, ya que se agregará una capa personalizada\n",
    "# para la tarea específica. Los pesos se inicializan con los pesos preentrenados en \"Imagenet\". El argumento \"input_shape\" \n",
    "# especifica el tamaño de entrada de las imágenes que se utilizarán en el modelo.\n",
    "\n",
    "vgg = VGG19(include_top= False, weights = \"imagenet\", input_shape=( img_height,img_width, 3))\n",
    "\n",
    "# \"vgg_layer_list\" almacena una lista de todas las capas en el modelo VGG19.\n",
    "\n",
    "vgg_layer_list = vgg.layers\n",
    "\n",
    "# \"model\" se utilizará para agregar capas personalizadas.\n",
    "\n",
    "model = Sequential ()\n",
    "\n",
    "# Copiaremos todas las capas del modelo VGG19 a \"model\"\n",
    "\n",
    "for layer in vgg_layer_list:\n",
    "    model.add(layer)\n",
    "    \n",
    "# Establecer el layer.trainable a False Esto congela los pesos de las capas de VGG19 y evita que se actualicen durante \n",
    "# el entrenamiento, lo que significa que solo las capas personalizadas agregadas posteriormente se entrenarán.\n",
    "    \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Se agrega una capa \"Flatten\" para aplanar la salida de la última capa convolucional de VGG19.\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# El Dropout ayuda a prevenir el sobreajuste al desactivar aleatoriamente algunas neuronas durante el entrenamiento.\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Se agrega una capa de activación 'softmax' para obtener probabilidades de clasificación para cada clase.\n",
    "\n",
    "model.add(Dense(numberOfClass))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd1d666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 192, 240, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 192, 240, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 96, 120, 64)       0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 96, 120, 128)      73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 96, 120, 128)      147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 48, 60, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 48, 60, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 48, 60, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 48, 60, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 48, 60, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 24, 30, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 24, 30, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 24, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 24, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 24, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 15, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 12, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21504)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              22021120  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,574,408\n",
      "Trainable params: 22,550,024\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4679cca",
   "metadata": {},
   "source": [
    "A continuación, ce crea una instancia del optimizador Adam llamada \"opt\" utilizando la clase \"Adam\" de Keras. Se especifican varios argumentos:\n",
    "\n",
    "- \"lr=0.0001\": Especifica la tasa de aprendizaje, que determina el tamaño de los pasos que el algoritmo de optimización toma para ajustar los pesos del modelo durante el entrenamiento. En este caso, se establece en 0.0001.\n",
    "- \"beta_1=0.9\": Especifica el valor para el parámetro beta_1 de Adam, que controla el decaimiento exponencial de los promedios móviles de primer orden.\n",
    "- \"beta_2=0.999\": Especifica el valor para el parámetro beta_2 de Adam, que controla el decaimiento exponencial de los promedios móviles de segundo orden.\n",
    "\n",
    "Con el método \"compile\" del modelo podremos configurar el proceso de entrenamiento. Se especifican varios argumentos:\n",
    "\n",
    "- \"optimizer=opt\": Selecciona el optimizador a utilizar durante el entrenamiento. En este caso, se utiliza el optimizador Adam configurado previamente.\n",
    "- \"loss='categorical_crossentropy'\": Especifica la función de pérdida que se utilizará para medir la discrepancia entre las etiquetas verdaderas y las predicciones del modelo durante el entrenamiento. En este caso, se utiliza la pérdida de entropía cruzada categórica, que es comúnmente utilizada en problemas de clasificación con múltiples clases.\n",
    "- \"metrics=['accuracy']\": Especifica las métricas que se calcularán y mostrarán durante el entrenamiento y la evaluación del modelo. En este caso, se utiliza la métrica de precisión (accuracy) para evaluar el rendimiento del modelo en términos de la clasificación correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c2cd40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c7e5044",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "        generator=train_generator,        \n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a32b9047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "318ac9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"hyundai\",\"lexus\",\"mazda\",\"mercedes\",\"opel\",\"skoda\",\"toyota\",\"volkswagen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "597da352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_evolution(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca86808",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_confusion_matrix(validation_generator, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac47c11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
